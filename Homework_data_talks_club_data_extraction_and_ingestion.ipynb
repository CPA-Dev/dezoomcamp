{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CPA-Dev/dezoomcamp/blob/main/Homework_data_talks_club_data_extraction_and_ingestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework**: Data talks club data engineering zoomcamp Data loading workshop\n",
        "\n",
        "Hello folks, let's practice what we learned - Loading data with the best practices of data engineering.\n",
        "\n",
        "Here are the exercises we will do\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mrTFv5nPClXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Use a generator\n",
        "\n",
        "Remember the concept of generator? Let's practice using them to futher our understanding of how they work.\n",
        "\n",
        "Let's define a generator and then run it as practice.\n",
        "\n",
        "**Answer the following questions:**\n",
        "\n",
        "- **Question 1: What is the sum of the outputs of the generator for limit = 5?**\n",
        "- **Question 2: What is the 13th number yielded**\n",
        "\n",
        "I suggest practicing these questions without GPT as the purpose is to further your learning."
      ],
      "metadata": {
        "id": "wLF4iXf-NR7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_root_generator(limit):\n",
        "    n = 1\n",
        "    while n <= limit:\n",
        "        yield n ** 0.5\n",
        "        n += 1\n",
        "\n",
        "# Example usage:\n",
        "limit = 13\n",
        "generator = square_root_generator(limit)\n",
        "total = 0\n",
        "for sqrt_value in generator:\n",
        "    total += sqrt_value\n",
        "    print(sqrt_value)\n",
        "\n",
        "print(total)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLng-bDJN4jf",
        "outputId": "3ef481a2-1f49-4cbb-f3ef-b9c7b8186c45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.4142135623730951\n",
            "1.7320508075688772\n",
            "2.0\n",
            "2.23606797749979\n",
            "2.449489742783178\n",
            "2.6457513110645907\n",
            "2.8284271247461903\n",
            "3.0\n",
            "3.1622776601683795\n",
            "3.3166247903554\n",
            "3.4641016151377544\n",
            "3.605551275463989\n",
            "32.854555867161245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xbe3q55zN43j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Append a generator to a table with existing data\n",
        "\n",
        "\n",
        "Below you have 2 generators. You will be tasked to load them to duckdb and answer some questions from the data\n",
        "\n",
        "1. Load the first generator and calculate the sum of ages of all people. Make sure to only load it once.\n",
        "2. Append the second generator to the same table as the first.\n",
        "3. **After correctly appending the data, calculate the sum of all ages of people.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vjWhILzGJMpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install \"dlt[duckdb]\" # Install dlt with all the necessary DuckDB dependencies"
      ],
      "metadata": {
        "id": "QyKWbkIh5wzm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dlt --version"
      ],
      "metadata": {
        "id": "uxgj6nr2517B",
        "outputId": "6906ee83-7477-4f71-e01d-358d873feaf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlt 0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "2MoaQcdLBEk6",
        "outputId": "8ab179b2-13a0-41ea-d5cd-ac29f9c7e44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ID': 1, 'Name': 'Person_1', 'Age': 26, 'City': 'City_A'}\n",
            "{'ID': 2, 'Name': 'Person_2', 'Age': 27, 'City': 'City_A'}\n",
            "{'ID': 3, 'Name': 'Person_3', 'Age': 28, 'City': 'City_A'}\n",
            "{'ID': 4, 'Name': 'Person_4', 'Age': 29, 'City': 'City_A'}\n",
            "{'ID': 5, 'Name': 'Person_5', 'Age': 30, 'City': 'City_A'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PipelineStepFailed",
          "evalue": "Pipeline execution failed at stage load when processing package 1707432453.5507383 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTerminalException'>\nBinder Error: Ambiguous reference to catalog or schema \"append_db\" - use a fully qualified path like \"append_db.append_db\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/sql_client.py\u001b[0m in \u001b[0;36m_wrap_gen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_native_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/impl/duckdb/sql_client.py\u001b[0m in \u001b[0;36mexecute_query\u001b[0;34m(self, query, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mouter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/impl/duckdb/sql_client.py\u001b[0m in \u001b[0;36mexecute_query\u001b[0;34m(self, query, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mDuckDBDBApiCursorImpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBinderException\u001b[0m: Binder Error: Ambiguous reference to catalog or schema \"append_db\" - use a fully qualified path like \"append_db.append_db\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDatabaseTerminalException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msignals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLoadInfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_step_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/common/runners/pool_runner.py\u001b[0m in \u001b[0;36mrun_pool\u001b[0;34m(config, run_f)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running pool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0m_run_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;31m# for next run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/common/runners/pool_runner.py\u001b[0m in \u001b[0;36m_run_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mrun_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/load/load.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, pool)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_info_start_load_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_single_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/load/load.py\u001b[0m in \u001b[0;36mload_single_package\u001b[0;34m(self, load_id, schema)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0;31m# init job client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                 applied_update = self._init_client(\n\u001b[0m\u001b[1;32m    449\u001b[0m                     \u001b[0mjob_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/load/load.py\u001b[0m in \u001b[0;36m_init_client\u001b[0;34m(self, job_client, schema, expected_update, load_id, truncate_filter, truncate_staging_filter)\u001b[0m\n\u001b[1;32m    422\u001b[0m         )\n\u001b[0;32m--> 423\u001b[0;31m         applied_update = self._init_dataset_and_update_schema(\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0mjob_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtables_with_jobs\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdlt_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate_tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/load/load.py\u001b[0m in \u001b[0;36m_init_dataset_and_update_schema\u001b[0;34m(job_client, expected_update, update_tables, truncate_tables, staging_info)\u001b[0m\n\u001b[1;32m    397\u001b[0m         )\n\u001b[0;32m--> 398\u001b[0;31m         applied_update = job_client.update_stored_schema(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0monly_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/job_client_impl.py\u001b[0m in \u001b[0;36mupdate_stored_schema\u001b[0;34m(self, only_tables, expected_update)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mapplied_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTSchemaTables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mschema_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stored_schema_by_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstored_version_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/job_client_impl.py\u001b[0m in \u001b[0;36mget_stored_schema_by_hash\u001b[0;34m(self, version_hash)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT {self.version_table_schema_columns} FROM {name} WHERE version_hash = %s;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_row_to_schema_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/job_client_impl.py\u001b[0m in \u001b[0;36m_row_to_schema_info\u001b[0;34m(self, query, *args)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatabaseUndefinedRelation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/destinations/sql_client.py\u001b[0m in \u001b[0;36m_wrap_gen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_database_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseTerminalException\u001b[0m: Binder Error: Ambiguous reference to catalog or schema \"append_db\" - use a fully qualified path like \"append_db.append_db\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPipelineStepFailed\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e465496b9973>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpipeline_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"append_db\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"duckdb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"append_db\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mload_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeople_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"people\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpeople_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0mtrace_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_trace_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPipelineStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mstep_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mConfigSectionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             ):\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, destination, staging, dataset_name, credentials, table_name, write_disposition, columns, primary_key, schema, loader_file_format, schema_contract)\u001b[0m\n\u001b[1;32m    627\u001b[0m             )\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_file_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_file_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0mtrace_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_trace_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPipelineStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mstep_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# refresh live schemas in storage or import schema path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit_live_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;31m# save modified live schemas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlive_schemas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# add the state to container as a context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minjectable_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStateInjectableContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mConfigSectionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             ):\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dlt/pipeline/pipeline.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, destination, dataset_name, credentials, workers, raise_on_failed_jobs)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ml_ex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mstep_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_step_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             raise PipelineStepFailed(\n\u001b[0m\u001b[1;32m    510\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"load\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_load_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_ex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             ) from l_ex\n",
            "\u001b[0;31mPipelineStepFailed\u001b[0m: Pipeline execution failed at stage load when processing package 1707432453.5507383 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTerminalException'>\nBinder Error: Ambiguous reference to catalog or schema \"append_db\" - use a fully qualified path like \"append_db.append_db\""
          ]
        }
      ],
      "source": [
        "import dlt\n",
        "\n",
        "def people_1():\n",
        "    for i in range(1, 6):\n",
        "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 25 + i, \"City\": \"City_A\"}\n",
        "\n",
        "for person in people_1():\n",
        "    print(person)\n",
        "\n",
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"append_db\", destination=\"duckdb\", dataset_name=\"append_db\"\n",
        ")\n",
        "\n",
        "load_info = pipeline.run(people_1, table_name=\"people\")\n",
        "\n",
        "def people_2():\n",
        "    for i in range(3, 9):\n",
        "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 30 + i, \"City\": \"City_B\", \"Occupation\": f\"Job_{i}\"}\n",
        "\n",
        "\n",
        "for person in people_2():\n",
        "    print(person)\n",
        "\n",
        "\n",
        "# run the pipeline with default settings, and capture the outcome\n",
        "info = pipeline.run(people_2,\n",
        "\t\t\t\t\ttable_name=\"people\",\n",
        "\t\t\t\t\twrite_disposition=\"append\",\n",
        "\t\t\t\t\tmerge_key=\"record_hash\")\n",
        "\n",
        "# show the outcome\n",
        "print(info)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vtdTIm4fvQCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Merge a generator\n",
        "\n",
        "Re-use the generators from Exercise 2.\n",
        "\n",
        "A table's primary key needs to be created from the start, so load your data to a new table with primary key ID.\n",
        "\n",
        "Load your first generator first, and then load the second one with merge. Since they have overlapping IDs, some of the records from the first load should be replaced by the ones from the second load.\n",
        "\n",
        "After loading, you should have a total of 8 records, and ID 3 should have age 33.\n",
        "\n",
        "Question: **Calculate the sum of ages of all the people loaded as described above.**\n"
      ],
      "metadata": {
        "id": "pY4cFAWOSwN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution: First make sure that the following modules are installed:"
      ],
      "metadata": {
        "id": "kKB2GTB9oVjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the dependencies\n",
        "%%capture\n",
        "!pip install dlt[duckdb]"
      ],
      "metadata": {
        "id": "xTVvtyqrfVNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to do: homework :)"
      ],
      "metadata": {
        "id": "a2-PRBAkGC2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions? difficulties? We are here to help.\n",
        "- DTC data engineering course channel: https://datatalks-club.slack.com/archives/C01FABYF2RG\n",
        "- dlt's DTC cohort channel: https://dlthub-community.slack.com/archives/C06GAEX2VNX"
      ],
      "metadata": {
        "id": "PoTJu4kbGG0z"
      }
    }
  ]
}